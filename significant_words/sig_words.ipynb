{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant words\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Write a function that generates the most “significant” words in a file by comparing it to a larger corpus.\n",
    "The function should take three inputs:\n",
    "\n",
    "* A path to a corpus of texts [This can be the plaintext Shakespeare plays we’ve been working with, or any other corpus of texts you might want to put together]. e.g. ~/Desktop/texts/*.txt\n",
    "* A path for an individual file. e.g. ~/Desktop/texts/hamlet.txt\n",
    "* A number N representing the top N significant words to return\n",
    "\n",
    "You will need to compute tf-idf scores for all words in the individual file against the rest of the corpus.\n",
    "The function should return a list of tuples in the form [(wd1, score1), (wd2, score2), .... (wdN, scoreN)]\n",
    "\n",
    "### Part 2\n",
    "write a function that takes the following:\n",
    "\n",
    "* A path to a corpus of texts e.g. ~/Desktop/texts/*.txt\n",
    "* A path for an individual file. e.g. ~/Desktop/texts/hamlet.txt\n",
    "* A path for a second individual file. e.g. ~/Desktop/texts/macbeth.txt\n",
    "* A number N representing the top N significant words to return\n",
    "\n",
    "The function should find out which words are common among the topN words for each document and plot their tf-idf scores against each other as a scatterplot. If no words are common in the topN, the function should handle that case gracefully and print an error message suggesting the user increase the value of N.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt1\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(s, case = \"L\"):\n",
    "    if case == \"L\":\n",
    "        s = s.lower()\n",
    "    elif case == \"U\":\n",
    "        s = s.upper()\n",
    "    return s\n",
    "\n",
    "#new tokenize function\n",
    "def tokenize(s, tokenize_char=None):\n",
    "    punctuations = \"-,.?!;: \\n\\t\"\n",
    "    s = [t.strip(punctuations) for t in s.split(tokenize_char)]\n",
    "    s = [t for t in s if t != '']\n",
    "    return s\n",
    "\n",
    "def rawf_df(s, df=None):\n",
    "    rawf = defaultdict(int)\n",
    "    this_df = defaultdict(int)\n",
    "    for t in s:\n",
    "        rawf[t]+=1\n",
    "        this_df[t] = 1\n",
    "    if df != None:\n",
    "        df = defaultdict(int, df)#df casts an ordinary dict to default dict (in case someone supplies the wrong kind)\n",
    "    else:\n",
    "        df = defaultdict(int)\n",
    "    for t in this_df:\n",
    "        df[t]+=1\n",
    "    return rawf, df\n",
    "\n",
    "def rawf_df(s, df=None):\n",
    "    rawf = defaultdict(int)\n",
    "    this_df = defaultdict(int)\n",
    "    for t in s:\n",
    "        rawf[t]+=1\n",
    "        this_df[t] = 1\n",
    "    if df != None:\n",
    "        df = defaultdict(int, df)\n",
    "    else:\n",
    "        df = defaultdict(int)\n",
    "    for t in this_df:\n",
    "        df[t]+=1\n",
    "    return rawf, df\n",
    "\n",
    "def score_00(tf):\n",
    "    scores = sorted(tf.items(), key = lambda x: x[1], reverse = True)\n",
    "    return scores\n",
    "\n",
    "def score_01(tf, df, n):\n",
    "    #scores = [(t, tf[t]*(n/df[t])) for t in tf]\n",
    "    scores = [(t, float(tf[t]) * (float(n)/float(df[t])) ) for t in tf]\n",
    "    scores = sorted(scores, key = lambda x:x[1], reverse = True)\n",
    "    return scores\n",
    "\n",
    "import math\n",
    "def tf_idf(tf, df, n):\n",
    "    token_scores = []\n",
    "    for t in tf:\n",
    "        #xcore = tf[t]*math.log10(n/df[t])\n",
    "        score = tf[t]*math.log10(n/df[t])\n",
    "        token_scores.append((t,score))\n",
    "    return sorted(token_scores, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "def rf_text_over_rf_corpus(raw_freqs):\n",
    "    \n",
    "    all_text_relative_freqs = [rawf_to_tf(one_text_raw_freq) for one_text_raw_freq in raw_freqs]\n",
    "    \n",
    "    corpus_raw_freq = defaultdict(int)\n",
    "    \n",
    "    for one_text_raw_freq in raw_freqs:\n",
    "        for t, n in one_text_raw_freq.iteritems():\n",
    "            corpus_raw_freq[t] += n\n",
    "            \n",
    "    corpus_relative_freq = rawf_to_tf(corpus_raw_freq)\n",
    "        \n",
    "    all_texts_scores = []\n",
    "    \n",
    "    for one_text_relative_freq in all_text_relative_freqs:\n",
    "        one_text_scores = []\n",
    "        for t, relative_freq in one_text_relative_freq.iteritems():\n",
    "            one_text_scores.append([t, relative_freq / corpus_relative_freq[t]])\n",
    "        all_texts_scores.append(one_text_scores)\n",
    "        \n",
    "    return all_texts_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# PART 1\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def most_sig_words (path_to_corpus, path_to_indv, top_n):\n",
    "    '''\n",
    "    most_sig_words takes the path to all corpus, path to individual file, and \n",
    "    top n and computes the tf-idf for all words in the individual file against\n",
    "    the rest of the corpus\n",
    "    pram: str - path_to_corpus\n",
    "    pram: str - path_to_indv\n",
    "    pram: int - top_n\n",
    "    return list of tuples (eg: [(wd1, score1), (wd2, score2), .... (wdN, scoreN)])\n",
    "    '''\n",
    "    plays = path_to_corpus\n",
    "    files = glob.glob(plays)\n",
    "    playnames = [os.path.split(play)[1][:-4].replace('_', ' ').title() for play in files]\n",
    "\n",
    "    keytext = os.path.split(path_to_indv)[1][:-4].replace('_', ' ').title()\n",
    "    key_index = playnames.index(keytext)\n",
    "\n",
    "    raw_freqs = []\n",
    "    df = {}\n",
    "\n",
    "    for f in files:\n",
    "        text = tokenize(preprocess(open(f, 'r').read()))\n",
    "        rawf, df = rawf_df(text, df)\n",
    "        raw_freqs.append(rawf)\n",
    "\n",
    "    scores = tf_idf(raw_freqs[key_index], df, len(raw_freqs))\n",
    "    print\n",
    "    print scores[:top_n]\n",
    "\n",
    "\n",
    "    all_texts_scores = rf_text_over_rf_corpus(raw_freqs)\n",
    "    scores = sorted(all_texts_scores[key_index], key = lambda x:x[1], reverse = True)\n",
    "    print\n",
    "    print scores[:top_n]\n",
    "    \n",
    "# most_sig_words(\"../corpora/shakespeare_plaintext/*.txt\", \"../corpora/shakespeare_plaintext/macbeth.txt\", 25 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# PART 2\n",
    "# ---------------------------------------------------------------------------\n",
    "def common_topn(path_to_corpus, path_to_indv1, path_to_indv2, top_n):\n",
    "    '''\n",
    "    common_topn takes the path to all corpus, path to 2 individual files, and \n",
    "    top n and return common words among the topN words for each document and plot results\n",
    "    pram: str - path_to_corpus\n",
    "    pram: str - path_to_indv1\n",
    "    pram: str - path_to_indv2\n",
    "    pram: int - top_n\n",
    "    return list of tuples (eg: [(wd1, score1file1, score1file2), (wd2, score2file1, score2file2), .... (wdN, scoreNfile2, scoreNfile2)])\n",
    "            and scatter plot scorefile1 vs scorefile2\n",
    "    '''\n",
    "    plays = path_to_corpus\n",
    "    files = glob.glob(plays)\n",
    "    playnames = [os.path.split(play)[1][:-4].replace('_', ' ').title() for play in files]\n",
    "\n",
    "    keytext1 = os.path.split(path_to_indv1)[1][:-4].replace('_', ' ').title()\n",
    "    keytext2 = os.path.split(path_to_indv2)[1][:-4].replace('_', ' ').title()\n",
    "    key_index1 = playnames.index(keytext1)\n",
    "    key_index2 = playnames.index(keytext2)\n",
    "\n",
    "    raw_freqs = []\n",
    "    df = {}\n",
    "\n",
    "    for f in files:\n",
    "        text = tokenize(preprocess(open(f, 'r').read()))\n",
    "        rawf, df = rawf_df(text, df)\n",
    "        raw_freqs.append(rawf)\n",
    "\n",
    "    scores1 = tf_idf(raw_freqs[key_index1], df, len(raw_freqs))\n",
    "    scores2 = tf_idf(raw_freqs[key_index2], df, len(raw_freqs))\n",
    "\n",
    "    common_words = []\n",
    "    tf_idf_1 = []\n",
    "    tf_idf_2 = []\n",
    "    labels = []\n",
    "    for s1 in scores1[:top_n]:\n",
    "        for s2 in scores2[:top_n]:\n",
    "            if s1[0] == s2[0]:\n",
    "                tf_idf_1.append(s1[1])\n",
    "                tf_idf_2.append(s2[1])\n",
    "                labels.append(s1[0])\n",
    "                common_words.append((s1[0], s1[1], s2[1]))\n",
    "    \n",
    "    #if common words then plot\n",
    "    if common_words:\n",
    "        print common_words\n",
    "        plt1.figure(figsize=(15,12))\n",
    "        plt1.xlabel(\"tf-idf file 1\")\n",
    "        plt1.ylabel(\"tf-idf file 2\")\n",
    "        plt1.scatter(tf_idf_1, tf_idf_2, s=200, alpha=.5)\n",
    "        for i, l in enumerate(labels):\n",
    "            plt1.text(tf_idf_1[i], tf_idf_2[i], l)\n",
    "    else:\n",
    "        print \"Increase value of N to find common terms\"\n",
    "\n",
    "#     all_texts_scores = rf_text_over_rf_corpus(raw_freqs)\n",
    "#     scores = sorted(all_texts_scores[key_index], key = lambda x:x[1], reverse = True)\n",
    "#     print\n",
    "#     print scores[:top_n]\n",
    "\n",
    "common_topn(\"../corpora/shakespeare_plaintext/*.txt\", \"../corpora/shakespeare_plaintext/macbeth.txt\", \"../corpora/shakespeare_plaintext/othello.txt\", 60 )\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
