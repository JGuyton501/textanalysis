{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textacy, with the Inaugural Addresses . . . \n",
    "\n",
    "[textacy Quick Start](https://chartbeat-labs.github.io/textacy/getting_started/quickstart.html)\n",
    "\n",
    "[textacy API documentation](https://chartbeat-labs.github.io/textacy/api_reference.html#)\n",
    "\n",
    "[textacy github repo](https://github.com/chartbeat-labs/textacy)\n",
    "\n",
    "\n",
    "## . . . and topic modeling . . . \n",
    "\n",
    "[Mallet](http://mallet.cs.umass.edu/), the java topic modeling package we use most often.\n",
    "\n",
    "[David Mimno explains Topic Modeling](https://vimeo.com/53080123).  Mimno is the maintainer of Mallet.\n",
    "\n",
    "[Ben Schmidt applies topic modeling to ship logs](http://sappingattention.blogspot.com/2012/11/when-you-have-mallet-everything-looks.html)\n",
    "\n",
    "[Scott Weingart, \"Topic Modeling for Humanists: A Guided Tour\"](http://www.scottbot.net/HIAL/index.html@p=19113.html)\n",
    "\n",
    "[Mining the Dispatch](http://dsl.richmond.edu/dispatch/), an exemplary application of topic modeling to a set of historical newspaper data.\n",
    "\n",
    "[My toy topic modeller](https://talus.artsci.wustl.edu/malletTalk/toyTopicModeller.py), written in python.\n",
    "\n",
    "[My github repo for \"understanding_mallet\"](https://github.com/spenteco/understanding_mallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But first we have to get textacy re-installed\n",
    "\n",
    "### First, is it already installed?\n",
    "\n",
    "If the **correct, latest** version is installed, the next cell should output:\n",
    "\n",
    "    0.6.0\n",
    "    2.0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.0\n",
      "2.0.9\n"
     ]
    }
   ],
   "source": [
    "import textacy, spacy\n",
    "\n",
    "print textacy.__version__\n",
    "print spacy.__version__\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### If the previous cell returned \"dotted\" numbers, but not the right one . . . \n",
    "\n",
    ". . . unnstall textacy.  You should be able to run the next cell in both Mac and Windows.\n",
    "\n",
    "### If the previous cell returned \"ImportError: No module named textact\" . . . \n",
    "\n",
    ". . . or a similar message, then you can skip the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/JGuyton/anaconda\n",
      "\n",
      "  removed specs: \n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "    spacy: 2.0.9-py27h1702cab_0\n",
      "\n",
      "Preparing transaction: - \b\bdone\n",
      "Verifying transaction: | \b\bdone\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"
     ]
    }
   ],
   "source": [
    "#!conda uninstall -y textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problems seem to be related to PATH\n",
    "\n",
    "### For Mac only\n",
    "\n",
    "First, the next cell will return something like\n",
    "\n",
    "    /home/spenteco/anaconda2/bin/python\n",
    "    \n",
    "### For Windows\n",
    "\n",
    "I don't have a Windows machine with a functional Anaconda for testing this (we have Anaconda<br/>\n",
    "on Windows, but all the installations are broken).  In any case, you don't need to run the<br/>\n",
    "Windows command (and can't, because it's not a Windows command!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/JGuyton/anaconda/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinstall textacy and the spacy models\n",
    "\n",
    "### For Mac\n",
    "\n",
    "We're taking the path (everything through \"bin/\" fro the first, textacy install command;<br/>|everything for the second command) to specify which \"pip\" and which \"python\" we want<br/>to use (there are likely several on your computer).  In the following cell, modify the commands:\n",
    "\n",
    "!**/home/spenteco/anaconda2/bin/**pip install textacy\n",
    "\n",
    "!**/home/spenteco/anaconda2/bin/python** -m spacy download en\n",
    "\n",
    "So that the bolded parts match whatever was output by the \"which\" command.\n",
    "\n",
    "### For Windows\n",
    "\n",
    "I'm working from a memory of the one time I saw this sort of package-installation problem in Windows.  But, I think you can:\n",
    "\n",
    "1.  Find \"Anaconda Prompt\" in the start menu, and open it.\n",
    "\n",
    "2.  In the \"Anaconda Prompt\", run:\n",
    "\n",
    "    pip install textacy\n",
    "\n",
    "    python -m spacy download en\n",
    "\n",
    "### When you're done, restart the notebook Kernel (Mac and Windows)\n",
    "\n",
    "See the menu at the top of the Jupyter notebook page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 15.1MB/s \n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /Users/JGuyton/anaconda/lib/python2.7/site-packages\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/JGuyton/anaconda/lib/python2.7/site-packages/en_core_web_sm -->\n",
      "    /Users/JGuyton/anaconda/lib/python2.7/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !/Users/JGuyton/anaconda/bin/pip install textacy\n",
    "\n",
    "!/Users/JGuyton/anaconda/bin/python -m spacy download en\n",
    "\n",
    "# DONT FORGET TO RESTART THE KERNEL WHEN YOU'RE DONE . . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did it work?\n",
    "\n",
    "The next cell should display:\n",
    "\n",
    "    0.6.0\n",
    "    2.0.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.0\n",
      "2.0.9\n"
     ]
    }
   ],
   "source": [
    "import textacy, spacy\n",
    "\n",
    "print textacy.__version__\n",
    "print spacy.__version__\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Text Analysis . . . \n",
    "\n",
    ". . . using the Inaugural Address corpus, which has these files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m10_adams_john_quincy_1825.txt\u001b[m\u001b[m  \u001b[31m37_roosevelt_franklin_1933.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m11_jackson_1829.txt\u001b[m\u001b[m            \u001b[31m38_roosevelt_franklin_1937.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m12_jackson_1833.txt\u001b[m\u001b[m            \u001b[31m39_roosevelt_franklin_1941.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m13_van_buren_1837.txt\u001b[m\u001b[m          \u001b[31m3_adams_john_1797.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m14_harrison_1841.txt\u001b[m\u001b[m           \u001b[31m40_roosevelt_franklin_1945.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m15_polk_1845.txt\u001b[m\u001b[m               \u001b[31m41_truman_1949.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m16_taylor_1849.txt\u001b[m\u001b[m             \u001b[31m42_eisenhower_1953.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m17_pierce_1853.txt\u001b[m\u001b[m             \u001b[31m43_eisenhower_1957.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m18_buchanan_1857.txt\u001b[m\u001b[m           \u001b[31m44_kennedy_1961.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m19_lincoln_1861.txt\u001b[m\u001b[m            \u001b[31m45_johnson_1965.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m1_washington_1789.txt\u001b[m\u001b[m          \u001b[31m46_nixon_1969.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m20_lincoln_1865.txt\u001b[m\u001b[m            \u001b[31m47_nixon_1973.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m21_grant_1869.txt\u001b[m\u001b[m              \u001b[31m48_carter_1977.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m22_grant_1873.txt\u001b[m\u001b[m              \u001b[31m49_reagan_1981.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m23_hayes_1877.txt\u001b[m\u001b[m              \u001b[31m4_jefferson_1801.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m24_garfield_1881.txt\u001b[m\u001b[m           \u001b[31m50_reagan_1985.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m25_cleveland_1885.txt\u001b[m\u001b[m          \u001b[31m51_bush_george_h_w_1989.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m26_harrison_1889.txt\u001b[m\u001b[m           \u001b[31m52_clinton_1993.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m27_cleveland_1893.txt\u001b[m\u001b[m          \u001b[31m53_clinton_1997.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m28_mckinley_1897.txt\u001b[m\u001b[m           \u001b[31m54_bush_george_w_2001.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m29_mckinley_1901.txt\u001b[m\u001b[m           \u001b[31m55_bush_george_w_2005.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m2_washington_1793.txt\u001b[m\u001b[m          \u001b[31m56_obama_2009.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m30_roosevelt_theodore_1905.txt\u001b[m\u001b[m \u001b[31m57_obama_2013.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m31_taft_1909.txt\u001b[m\u001b[m               \u001b[31m58_trump_2017.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m32_wilson_1913.txt\u001b[m\u001b[m             \u001b[31m5_jefferson_1805.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m33_wilson_1917.txt\u001b[m\u001b[m             \u001b[31m6_madison_1809.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m34_harding_1921.txt\u001b[m\u001b[m            \u001b[31m7_madison_1813.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m35_coolidge_1925.txt\u001b[m\u001b[m           \u001b[31m8_monroe_1817.txt\u001b[m\u001b[m\r\n",
      "\u001b[31m36_hoover_1929.txt\u001b[m\u001b[m             \u001b[31m9_monroe_1821.txt\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls corpora/inaugural_addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the corpus through Spacy\n",
    "\n",
    "We're creating \"corpus_input\", which is a list of dictionaries.  Each dictionary<br/> \n",
    "in the \"corpus_input\" represents one inaugural address.  For each inaugural address,<br/>\n",
    "we're keeping the year, the president, the raw text, and the \"selected_text\".\n",
    "\n",
    "\"Selected text\" is the lemma form of the words in the inaugural address.  I'm<br/>\n",
    "dropping stopwords, punctuation, and space.  I collect the lemmas/tokens for<br/>\n",
    "\"selected_text\", then join them into one string, with one space between lemmas.tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import glob, codecs, re\n",
    "\n",
    "corpus_input = []\n",
    "\n",
    "for path_to_file in glob.glob('corpora/inaugural_addresses/*.txt'):\n",
    "    \n",
    "    f = path_to_file.split('/')[-1].replace('.txt', '')\n",
    "    \n",
    "    year = int(f.split('_')[-1])\n",
    "    president = '_'.join(f.split('_')[1:-1])\n",
    "    \n",
    "    raw_text = re.sub('\\s+', ' ', codecs.open(path_to_file, 'r', encoding='utf-8').read())\n",
    "    \n",
    "    selected_tokens = []\n",
    "    doc = nlp(unicode(raw_text))\n",
    "    for t in doc:\n",
    "        if t.is_stop == False and t.is_punct == False and t.is_space == False:\n",
    "            if t.lemma_ != '-PRON-':\n",
    "                selected_tokens.append(t.lemma_)\n",
    "    \n",
    "    corpus_input.append({'year': year, \n",
    "                   'president': president, \n",
    "                   'raw_text': raw_text, \n",
    "                   'selected_text': ' '.join(selected_tokens)})\n",
    "    \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting corpus_input\n",
    "\n",
    "Does it contain what I expect it to contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(corpus_input) 58\n",
      "\n",
      "1789 washington\n",
      "\n",
      "Fellow-Citizens of the Senate and of the House of Representatives: Among the vicissitudes incident to life no event could have filled me with greater anxieties than that of which the notification was \n",
      "\n",
      "fellow citizens senate house representatives among vicissitude incident life event fill great anxiety notification transmit order receive 14th day present month on hand summon country voice hear vener\n"
     ]
    }
   ],
   "source": [
    "corpus_input.sort(key = lambda t: t['year'])\n",
    "\n",
    "print\n",
    "print 'len(corpus_input)', len(corpus_input)\n",
    "\n",
    "print\n",
    "print corpus_input[0]['year'], corpus_input[0]['president']\n",
    "print\n",
    "print corpus_input[0]['raw_text'][:200]\n",
    "print\n",
    "print corpus_input[0]['selected_text'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1789 washington len(raw_text) 8610\n",
      "1793 washington len(raw_text) 770\n",
      "1797 adams_john len(raw_text) 13862\n",
      "1801 jefferson len(raw_text) 10091\n",
      "1805 jefferson len(raw_text) 12892\n",
      "1809 madison len(raw_text) 6991\n",
      "1813 madison len(raw_text) 7147\n",
      "1817 monroe len(raw_text) 19864\n",
      "1821 monroe len(raw_text) 26285\n",
      "1825 adams_john_quincy len(raw_text) 17724\n",
      "1829 jackson len(raw_text) 6785\n",
      "1833 jackson len(raw_text) 7031\n",
      "1837 van_buren len(raw_text) 23370\n",
      "1841 harrison len(raw_text) 49677\n",
      "1845 polk len(raw_text) 28660\n",
      "1849 taylor len(raw_text) 6594\n",
      "1853 pierce len(raw_text) 20043\n",
      "1857 buchanan len(raw_text) 16774\n",
      "1861 lincoln len(raw_text) 20930\n",
      "1865 lincoln len(raw_text) 3904\n",
      "1869 grant len(raw_text) 6450\n",
      "1873 grant len(raw_text) 7695\n",
      "1877 hayes len(raw_text) 14881\n",
      "1881 garfield len(raw_text) 17711\n",
      "1885 cleveland len(raw_text) 10106\n",
      "1889 harrison len(raw_text) 26127\n",
      "1893 cleveland len(raw_text) 12304\n",
      "1897 mckinley len(raw_text) 23618\n",
      "1901 mckinley len(raw_text) 13398\n",
      "1905 roosevelt_theodore len(raw_text) 5566\n",
      "1909 taft len(raw_text) 32101\n",
      "1913 wilson len(raw_text) 9554\n",
      "1917 wilson len(raw_text) 8351\n",
      "1921 harding len(raw_text) 20244\n",
      "1925 coolidge len(raw_text) 23910\n",
      "1929 hoover len(raw_text) 22564\n",
      "1933 roosevelt_franklin len(raw_text) 10865\n",
      "1937 roosevelt_franklin len(raw_text) 10555\n",
      "1941 roosevelt_franklin len(raw_text) 7496\n",
      "1945 roosevelt_franklin len(raw_text) 2997\n",
      "1949 truman len(raw_text) 13593\n",
      "1953 eisenhower len(raw_text) 13877\n",
      "1957 eisenhower len(raw_text) 9085\n",
      "1961 kennedy len(raw_text) 7538\n",
      "1965 johnson len(raw_text) 8043\n",
      "1969 nixon len(raw_text) 11511\n",
      "1973 nixon len(raw_text) 9908\n",
      "1977 carter len(raw_text) 6842\n",
      "1981 reagan len(raw_text) 13692\n",
      "1985 reagan len(raw_text) 14503\n",
      "1989 bush_george_h_w len(raw_text) 12476\n",
      "1993 clinton len(raw_text) 9134\n",
      "1997 clinton len(raw_text) 12136\n",
      "2001 bush_george_w len(raw_text) 8957\n",
      "2005 bush_george_w len(raw_text) 11898\n",
      "2009 obama len(raw_text) 13356\n",
      "2013 obama len(raw_text) 11955\n",
      "2017 trump len(raw_text) 8434\n"
     ]
    }
   ],
   "source": [
    "print\n",
    "for text in corpus_input:\n",
    "    print text['year'], text['president'], 'len(raw_text)', len(text['raw_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass corpus_input to textacy\n",
    "\n",
    "It's basically one operation.  In fact, **I think** it's possible to go<br/>\n",
    "from-the-disk-to-corpus in one step, without processing the texts through<br/>\n",
    "spacy . . . I think that would look something like:\n",
    "\n",
    "    corpus = textacy.Corpus(\n",
    "                u'en', \n",
    "                texts = [unicode(open(f).read()) for f in sorted('corpora/inaugural_addresses/*.txt'))],\n",
    "                metadatas = [{'file_name': i['year'], f.split('/')[-1] for f in sorted('corpora/inaugural_addresses/*.txt'))])\n",
    "                \n",
    "Note that I'm simplifying \"metadatas\".\n",
    "\n",
    "Why go straight from the disk to textacy, without going through spacy first?<br/>\n",
    "Because **I seem to recall** that the textacy vectorizer supports a wide range<br/>\n",
    "of \"filters\", which provide much of the drop-stopword, etc function which is<br/>\n",
    "in the spacy code in the cell above.\n",
    "\n",
    "Note also that we could wrap \"unicode(open(f).read())\" in a function which<br/>\n",
    "performed the NLP word selection and lemmatization processes on a single<br/>\n",
    "text, which would effectively get us the same thing.\n",
    "\n",
    "Nevertheless, I wanted to demonstrate passing the date through spacy<br/>\n",
    "because you may at some point want to use some other nlp package to filter,<br/>\n",
    "lemmatize, etc, so I wanted to demonstrate how to do that.\n",
    "\n",
    "### The spacy docs for corpus\n",
    "\n",
    "https://chartbeat-labs.github.io/textacy/getting_started/quickstart.html#working-with-many-texts\n",
    "\n",
    "https://chartbeat-labs.github.io/textacy/api_reference.html#module-textacy.corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(corpus) 58\n",
      "\n",
      "<class 'textacy.corpus.Corpus'>\n",
      "\n",
      "<class 'textacy.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "corpus = textacy.Corpus(\n",
    "            u'en', \n",
    "            texts = [unicode(i['selected_text']) for i in corpus_input],\n",
    "            metadatas = [{'year': i['year'], 'president': i['president']} for i in corpus_input])\n",
    "\n",
    "print 'len(corpus)', len(corpus)\n",
    "\n",
    "print\n",
    "print type(corpus)\n",
    "#print dir(corpus)\n",
    "\n",
    "print\n",
    "print type(corpus[0])\n",
    "#print dir(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the resulting textacy corpus . . . \n",
    "\n",
    " . . . comparing it to the \"corpus_input\" data.  Did I goof up<br/>\n",
    " anything?  **It's been known to happen.**\n",
    " \n",
    " Note that corpus.n_sents seems small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1789 washington fellow citizens senate house representatives among\n",
      "{'president': 'washington', 'year': 1789} fellow citizens senate house representatives among\n",
      "\n",
      "1793 washington call voice country execute function chief magistra\n",
      "{'president': 'washington', 'year': 1793} call voice country execute function chief magistra\n",
      "\n",
      "1797 adams_john when perceive early time middle course america rem\n",
      "{'president': 'adams_john', 'year': 1797} when perceive early time middle course america rem\n",
      "\n",
      "1801 jefferson call undertake duty executive office country avail\n",
      "{'president': 'jefferson', 'year': 1801} call undertake duty executive office country avail\n",
      "\n",
      "1805 jefferson proceeding fellow citizen qualification constituti\n",
      "{'president': 'jefferson', 'year': 1805} proceeding fellow citizen qualification constituti\n",
      "\n",
      "docs in corpus 58\n",
      "sentences in corpus 437\n",
      "tokens in corpus 60569\n",
      "\n",
      "len(test_all_tokens) 60531\n",
      "len(test_n_unique_tokens) 6675\n"
     ]
    }
   ],
   "source": [
    "test_n_unique_tokens = []\n",
    "for c in corpus_input:\n",
    "    test_n_unique_tokens += re.split('\\s+', c['selected_text'])\n",
    "\n",
    "test_all_tokens =  test_n_unique_tokens\n",
    "test_n_unique_tokens = list(set(test_n_unique_tokens))\n",
    "\n",
    "for a in range(0, 5):\n",
    "    \n",
    "    print\n",
    "    print corpus_input[a]['year'], corpus_input[a]['president'], corpus_input[a]['selected_text'][:50]\n",
    "    \n",
    "    print corpus[a].metadata, corpus[a].text[:50]\n",
    "    \n",
    "print\n",
    "print 'docs in corpus', corpus.n_docs\n",
    "print 'sentences in corpus', corpus.n_sents\n",
    "print 'tokens in corpus', corpus.n_tokens\n",
    "print\n",
    "print 'len(test_all_tokens)', len(test_all_tokens)\n",
    "print 'len(test_n_unique_tokens)', len(test_n_unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords, too easy.\n",
    "\n",
    "Note the strange import.  Simply importing \"textacy\" doesn't work for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1789 washington\n",
      "\n",
      "government, public, duty, country, great, citizen, hand, present, people,\n",
      "nation, nature, liberty, united, circumstance, measure, happiness,\n",
      "qualification, view, care, character\n",
      "\n",
      "1793 washington\n",
      "\n",
      "oath, country, solemn, execute, present, function, witness, chief, subject,\n",
      "magistrate, punishment, occasion, constitutional, proper, injunction, high,\n",
      "sense, instance, entertain, distinguished\n",
      "\n",
      "1797 adams_john\n",
      "\n",
      "people, nation, government, country, good, constitution, state, power, justice,\n",
      "legislature, public, mind, honor, foreign, great, spirit, peace, party, citizen,\n",
      "form\n",
      "\n",
      "1801 jefferson\n",
      "\n",
      "government, good, man, principle, peace, safety, opinion, power, country,\n",
      "public, form, nation, confidence, error, happiness, honest, right, citizen, law,\n",
      "fellow\n",
      "\n",
      "1805 jefferson\n",
      "\n",
      "public, state, interest, duty, law, citizen, constitution, limit, good, country,\n",
      "time, nation, place, false, power, reason, fellow, mind, foreign, press\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import textacy.keyterms\n",
    "\n",
    "for doc in corpus[:5]:\n",
    "    print\n",
    "    print doc.metadata['year'], doc.metadata['president']\n",
    "    print\n",
    "    top_words = []\n",
    "    for w in textacy.keyterms.textrank(doc, n_keyterms=20):\n",
    "        top_words.append(w[0])\n",
    "    print '\\n'.join(textwrap.wrap(', '.join(top_words), 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus to document-term matrix . . . \n",
    "\n",
    "Lots of settings.  The doc is pretty good:\n",
    "\n",
    "https://chartbeat-labs.github.io/textacy/getting_started/quickstart.html#analyze-a-corpus\n",
    "\n",
    "https://chartbeat-labs.github.io/textacy/api_reference.html#vectorizers\n",
    "\n",
    "(Note that in the API, see **textacy.vsm.vectorizers.Vectorizer**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<58x6494 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 32492 stored elements in Compressed Sparse Row format>\n",
      "\n",
      "(58, 6494)\n"
     ]
    }
   ],
   "source": [
    "# FOR TD-IDF WEIGHTS\n",
    "#vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=True, apply_dl=True)\n",
    "\n",
    "# FOR RAW WORD COUNTS\n",
    "#vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=False, apply_dl=False)\n",
    "\n",
    "# FOR RELATIVE FREQUENCY\n",
    "vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=False, apply_dl=True)\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform((doc.to_terms_list(ngrams=1, named_entities=True, as_strings=True) \n",
    "                                               for doc in corpus))\n",
    "\n",
    "print\n",
    "print repr(doc_term_matrix)\n",
    "#print\n",
    "#print dir(doc_term_matrix)\n",
    "print\n",
    "print doc_term_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the document-term matrix\n",
    "\n",
    "Convert the sparse matrix to a dense matrix (i.e., one with all the zeros).\n",
    "\n",
    "Inspect in various ways.  Does it look reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matrix([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.03205853,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        ..., \n",
      "        [ 0.        ,  0.37300192,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.29688261,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ],\n",
      "        [ 0.        ,  0.19857537,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ]])\n",
      "\n",
      "(58, 6494)\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04170288281141495, 0.04170288281141495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "58 6494\n",
      "\n",
      "14th 0.0417028828114 ; 14th day present month 0.0417028828114 ; accomplish 0.0417028828114 ; accordingly 0.0417028828114 ; acknowledge 0.0417028828114 ; acquit 0.0417028828114 ; act 0.0417028828114 ; actual 0.0417028828114 ; actuate 0.0417028828114 ; add 0.0417028828114 ; addition 0.0417028828114 ; address 0.0417028828114 ; administration 0.0834057656228 ; adopt 0.0417028828114 ; adore 0.0417028828114 ; adorn 0.0417028828114 ; advance 0.0417028828114 ; advancement 0.0417028828114 ; advantage 0.0417028828114 ; advantageously 0.0417028828114 ; affair 0.0417028828114 ; affect 0.0417028828114 ; affection 0.0417028828114 ; affectionate 0.0417028828114 ; agency 0.0417028828114 ; aid 0.0417028828114 ; allot 0.0417028828114 ; almighty 0.0417028828114 ; alteration 0.0417028828114 ; american 0.0834057656228 ; animosity 0.0417028828114 ; anticipation 0.0417028828114 ; anxiety 0.0417028828114 ; appreciation 0.0417028828114 ; ardent 0.0417028828114 ; arduous 0.0417028828114 ; arise 0.0417028828114 ; article 0.0834057656228 ; assemblage 0.0417028828114 ; assemble 0.0417028828114 ; assure 0.0834057656228 ; asylum 0.0417028828114 ; attachment 0.0417028828114 ; attention 0.0417028828114 ; attribute 0.0417028828114 ; auspiciously 0.0417028828114 ; author 0.0417028828114 ; aver 0.0417028828114 ; avoid 0.0417028828114 ; await 0.0417028828114 ; awaken 0.0834057656228 ; behold 0.0417028828114 ; benediction 0.0417028828114 ; benefit 0.0417028828114 ; benign 0.0417028828114 ; bind 0.0417028828114 ; birth 0.0417028828114 ; blessing 0.0834057656228 ;\n"
     ]
    }
   ],
   "source": [
    "dense_doc_term_matrix = doc_term_matrix.todense()\n",
    "\n",
    "print\n",
    "print repr(dense_doc_term_matrix)\n",
    "print\n",
    "print dense_doc_term_matrix.shape\n",
    "\n",
    "list_doc_term_matrix = dense_doc_term_matrix.tolist()\n",
    "\n",
    "print\n",
    "print list_doc_term_matrix[0][:100]\n",
    "print\n",
    "print len(list_doc_term_matrix), len(list_doc_term_matrix[0])\n",
    "print\n",
    "for a in range(len(list_doc_term_matrix[0][:750])):\n",
    "    if list_doc_term_matrix[0][a] > 0:\n",
    "        print vectorizer.id_to_term[a], list_doc_term_matrix[0][a], ';',\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Let's do some actual text analysis\n",
    "\n",
    "We do three things here:\n",
    "\n",
    "1.  Create a vectorizer, then use it to create a document-term matrix.\n",
    "2.  Topic model using the document-term matrix.\n",
    "3.  List the words associated with each resulting topic.\n",
    "\n",
    "Lots of experimentation with Vectorizer parameters.  Raw word counts seem to work best.\n",
    "\n",
    "And lots of experimentation with \"n_topics\" in creating the topic model.  20 seemed<br/>\n",
    "reasonable for this demonstration.\n",
    "\n",
    "### The docs:\n",
    "\n",
    "https://chartbeat-labs.github.io/textacy/getting_started/quickstart.html#analyze-a-corpus\n",
    "\n",
    "https://chartbeat-labs.github.io/textacy/api_reference.html#topic-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spenteco/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('topic', 0, ':', u'today child democracy dream woman job promise friend remember problem')\n",
      "('topic', 1, ':', u'dream special hero today help weapon moral economic problem worthy')\n",
      "('topic', 2, ':', u'revenue increase direct economic desire providence reflect extend nature judgment')\n",
      "('topic', 3, ':', u'federal enforcement extend increase civilization business ability promote opinion community')\n",
      "('topic', 4, ':', u'opinion regard exist member object circumstance federal grant blessing period')\n",
      "('topic', 5, ':', u'democracy body sacred person continent early stock 1789 disruption clothe')\n",
      "('topic', 6, ':', u'pay object debt revenue defense dollar proper case regard trade')\n",
      "('topic', 7, ':', u'civilization today opinion supreme industrial business promote add evil prove')\n",
      "('topic', 8, ':', u'offense false occasion draw extend pay whatsoever truth cover cease')\n",
      "('topic', 9, ':', u'set wish counsel industrial child problem process wrong affair use')\n",
      "('topic', 10, ':', u'renewal today season drift idea challenge sake posterity capitol spring')\n",
      "('topic', 11, ':', u'today help child promise friend word moment build democracy challenge')\n",
      "('topic', 12, ':', u'today voice promise help democracy constitutional moment arrive occasion create')\n",
      "('topic', 13, ':', u'ought increase opinion federal protection fail money prove permanent independence')\n",
      "('topic', 14, ':', u'pay tax age revenue increase today department race number reduce')\n",
      "('topic', 15, ':', u'economic civilization business help democracy federal ideal international ought problem')\n",
      "('topic', 16, ':', u'importance help afford exist revenue regard sovereignty today claim defense')\n",
      "('topic', 17, ':', u'revenue increase territory proper object protection business ought trade exist')\n",
      "('topic', 18, ':', u'abroad role build today era challenge help structure proud learn')\n",
      "('topic', 19, ':', u'help extend want revenue recognize constitutional period importance enjoy firm')\n"
     ]
    }
   ],
   "source": [
    "# FOR TD-IDF WEIGHTS\n",
    "#vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=True, apply_dl=True,  min_df=2, max_df=40)\n",
    "\n",
    "# FOR RAW WORD COUNTS\n",
    "#vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=False, apply_dl=False,  min_df=2, max_df=40)\n",
    "#vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=False, apply_dl=False)\n",
    "\n",
    "# FOR RAW WORD COUNT.   LOW max_df VALUE REMOVES THINGS LIKE 'government' AND 'america' ANd SEEMS TO GIVE THE BEST RESULT\n",
    "vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=False, apply_dl=False,  min_df=2, max_df=26)\n",
    "\n",
    "# FOR RELATIVE FREQUENCY\n",
    "#vectorizer = textacy.Vectorizer(tf_type='linear', apply_idf=False, apply_dl=True)\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform((doc.to_terms_list(ngrams=1, named_entities=True, as_strings=True) \n",
    "                                               for doc in corpus))\n",
    "\n",
    "model = textacy.TopicModel('lda', n_topics=20)\n",
    "model.fit(doc_term_matrix)\n",
    "\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "\n",
    "print \n",
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, top_n=10):\n",
    "    print('topic', topic_idx, ':', ' '.join(top_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the document-topic percentages?\n",
    "\n",
    "I.e., which topics make up what percentage of each document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre style=\"font-size:10px;\">                      0    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16   17   18   19\n",
       " 0 1789 washington                     1.00                                                                           \n",
       " 1 1793 washington                                                                                      0.96          \n",
       " 2 1797 adams_john                     1.00                                                                           \n",
       " 3 1801 jefferson                      1.00                                                                           \n",
       " 4 1805 jefferson                      0.40                0.35                                         0.25          \n",
       " 5 1809 madison                        1.00                                                                           \n",
       " 6 1813 madison                        1.00                                                                           \n",
       " 7 1817 monroe                         0.02                                                             0.98          \n",
       " 8 1821 monroe                                                                                          1.00          \n",
       " 9 1825 adams_john                     1.00                                                                           \n",
       "10 1829 jackson                        1.00                                                                           \n",
       "11 1833 jackson                        1.00                                                                           \n",
       "12 1837 van_buren                      1.00                                                                           \n",
       "13 1841 harrison                       1.00                                                                           \n",
       "14 1845 polk                           0.18                                                             0.81          \n",
       "15 1849 taylor                         0.26                                                             0.74          \n",
       "16 1853 pierce                         0.34                                                   0.61      0.05          \n",
       "17 1857 buchanan                                                                                        1.00          \n",
       "18 1861 lincoln                                                                                         1.00          \n",
       "19 1865 lincoln                                            0.99                                                       \n",
       "20 1869 grant                                                                                 0.11      0.88          \n",
       "21 1873 grant                                                                                           1.00          \n",
       "22 1877 hayes                          0.98                                                             0.02          \n",
       "23 1881 garfield                                                          0.02                          0.98          \n",
       "24 1885 cleveland                      0.71                                                   0.27      0.02          \n",
       "25 1889 harrison                                                                                        1.00          \n",
       "26 1893 cleveland                                                                             1.00                    \n",
       "27 1897 mckinley                                                                                        1.00          \n",
       "28 1901 mckinley                                                                                        1.00          \n",
       "29 1905 roosevelt_                                              1.00                                                  \n",
       "30 1909 taft                                                                                            1.00          \n",
       "31 1913 wilson                                                  1.00                                                  \n",
       "32 1917 wilson                                                  1.00                                                  \n",
       "33 1921 harding                                                                               1.00                    \n",
       "34 1925 coolidge                                                                              1.00                    \n",
       "35 1929 hoover                                                                                1.00                    \n",
       "36 1933 roosevelt_                                                                            1.00                    \n",
       "37 1937 roosevelt_                                                        0.36                0.60           0.03     \n",
       "38 1941 roosevelt_                          0.75                          0.25                                        \n",
       "39 1945 roosevelt_                                                        0.71                               0.28     \n",
       "40 1949 truman                                                                                1.00                    \n",
       "41 1953 eisenhower                                                        0.26                0.73                    \n",
       "42 1957 eisenhower                                                        1.00                                        \n",
       "43 1961 kennedy                                                           1.00                                        \n",
       "44 1965 johnson                                                           1.00                                        \n",
       "45 1969 nixon                                                             1.00                                        \n",
       "46 1973 nixon                                                             0.14                               0.85     \n",
       "47 1977 carter          1.00                                                                                          \n",
       "48 1981 reagan          0.84                                              0.16                                        \n",
       "49 1985 reagan                                                            1.00                                        \n",
       "50 1989 bush_georg                                                        1.00                                        \n",
       "51 1993 clinton                                                      0.27 0.73                                        \n",
       "52 1997 clinton                                                           1.00                                        \n",
       "53 2001 bush_georg                                                        0.81                0.18                    \n",
       "54 2005 bush_georg                                                        1.00                                        \n",
       "55 2009 obama                                                             1.00                                        \n",
       "56 2013 obama                                                             1.00                                        \n",
       "57 2017 trump                                                             1.00                                        </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def make_printable(topic_pcts):\n",
    "    printable_pcts = []\n",
    "    for pct in topic_pcts:\n",
    "        formatted_pct = '%.2f' % pct\n",
    "        if formatted_pct == '0.00':\n",
    "            formatted_pct = '    '\n",
    "        printable_pcts.append(formatted_pct)\n",
    "    return printable_pcts\n",
    "\n",
    "topic_headings = []\n",
    "for a in range(len(doc_topic_matrix[0])):\n",
    "    topic_headings.append(str(a).rjust(4))\n",
    "    \n",
    "results =[['  ', '    ', ' '.ljust(10)] + topic_headings]\n",
    "    \n",
    "for a in range(len(doc_topic_matrix)):\n",
    "    results.append([str(a).rjust(2), \n",
    "                    str(corpus[a].metadata['year']), \n",
    "                    corpus[a].metadata['president'][:10].ljust(10)] + \n",
    "                    make_printable(doc_topic_matrix[a]))\n",
    "\n",
    "output_text = []\n",
    "for r in results:\n",
    "    output_text.append(' '.join(r))\n",
    "    \n",
    "display(Markdown('<pre style=\"font-size:10px;\">{}</pre>'.format('\\n'.join(output_text))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the words associated with each topic\n",
    "\n",
    "I did this once.  I do it again, because I want to see more words, and I'd<br/>\n",
    "like something that doesn't result in a wide display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "topic 0 : today child democracy dream woman job promise friend remember problem cost\n",
      "million challenge courage conviction forward consider ideal person protection\n",
      "arm build bless dignity benefit credit program safe ancient value learn second\n",
      "increase use moral story debate politic journey mr stop period section community\n",
      "constitutional middle permit perfect lose write\n",
      "\n",
      "topic 1 : dream special hero today help weapon moral economic problem worthy ceremony\n",
      "group away create price renew goal federal tax child struggle share build\n",
      "monument afford commitment productivity reflect capacity confront inauguration\n",
      "ensure sufficient intention enhance arsenal adversary pay govern burden fall\n",
      "fate answer thank heal open endure tell value word\n",
      "\n",
      "topic 2 : revenue increase direct economic desire providence reflect extend nature\n",
      "judgment prevail business expect foundation tax democracy courage ought occur\n",
      "moral federal counsel weight representative enable material proceed devise\n",
      "relationship benefit britain resume contribution clearly discharge cultivate\n",
      "million race false mindful texas add interested manifest property recommend host\n",
      "produce father welfare\n",
      "\n",
      "topic 3 : federal enforcement extend increase civilization business ability promote\n",
      "opinion community education welfare ideal local aspiration contribute\n",
      "instrumentality integrity establish enforce preservation election exercise\n",
      "abroad criminal occasion adapt expenditure controversy involve happy expression\n",
      "settlement agency economic domination cooperation countryman directly encourage\n",
      "recent proper amendment branch child independence rest official class rightly\n",
      "\n",
      "topic 4 : opinion regard exist member object circumstance federal grant blessing period\n",
      "exercise department countryman effect domestic example sentiment establish claim\n",
      "promote error difficulty republican appear consider discharge welfare possess\n",
      "desire proper constitutional want legislature operation increase conduct\n",
      "instrument produce officer representative occasion affair independence\n",
      "improvement safety revolution source govern patriotism acknowledge\n",
      "\n",
      "topic 5 : democracy body sacred person continent early stock 1789 disruption clothe inform\n",
      "preservation freely midst understand peril doubt feed little washington write\n",
      "enterprise fire die build degree improvement daily intrust compact function\n",
      "branch frame successfully pause humane blaze infinite undertake instruct manner\n",
      "justify model inviolate coordinate county furnish perpetuate naught ideal\n",
      "\n",
      "topic 6 : pay object debt revenue defense dollar proper case regard trade privilege desire\n",
      "material opinion ought permit effect deal almighty light execute constitutional\n",
      "oppose happy collect exercise revolution provision prejudice ability exist\n",
      "treaty soon determination enforce federal accord especially enjoy term moment\n",
      "person vast specie amendment practicable importance religious determine burden\n",
      "\n",
      "topic 7 : civilization today opinion supreme industrial business promote add evil prove\n",
      "reflect ideal understanding blessing standard plan relationship protection\n",
      "mankind courage establish territory family trade exercise military suffer object\n",
      "renew create affair turn understand conscience sanction child woman extend truth\n",
      "enterprise operation development knowledge forget inspiration economic possible\n",
      "burden safety commercial\n",
      "\n",
      "topic 8 : offense false occasion draw extend pay whatsoever truth cover cease conflict\n",
      "slave press answer judge reason ago pray address enable altogether cherish\n",
      "urgent witness moral dare comfort judgment approve population enlargement\n",
      "chiefly direct strange consumption correspond art dread lessen habit collect\n",
      "encourage gather fully understanding experiment meantime opinion zeal providence\n",
      "\n",
      "topic 9 : set wish counsel industrial child problem process wrong affair use politic cost\n",
      "energy private alter woman eye fail body matter democratic mankind vision age\n",
      "regard wealth existence foundation build try single immediate weak draw\n",
      "continent struggle turn vital equally ago social count certain genius evil\n",
      "current mere deeply able year ago\n",
      "\n",
      "topic 10 : renewal today season drift idea challenge sake posterity capitol spring renew\n",
      "compete powerful million democracy child community raise embrace ideal founder\n",
      "resolve friend revolution forth help bold depression affect ceremony advantage\n",
      "summon vision peaceful able animosity engulf mission wander stagnant massive\n",
      "heroic construct pillar thoma calculation shadow division inherit family\n",
      "\n",
      "topic 11 : today help child promise friend word moment build democracy challenge dream\n",
      "woman forward voice turn bless family journey thank dignity million mr courage\n",
      "remember age share small young hard unity ago learn strive endure want choice\n",
      "deep job value light understand ideal create hear wealth join choose idea\n",
      "celebrate arm\n",
      "\n",
      "topic 12 : today voice promise help democracy constitutional moment arrive occasion create\n",
      "economic increase ago dream community share neighbor official ceremony repose\n",
      "safety witness endeavor distinguished defense build execution family entertain\n",
      "word rest federal previous learn violate proper try knowledge program\n",
      "international execute dignity function evil moral endure possibility wise\n",
      "presence remember\n",
      "\n",
      "topic 13 : ought increase opinion federal protection fail money prove permanent\n",
      "independence ideal event circumstance extend problem amendment constitutional\n",
      "object controversy local proper little evil enforce promote expenditure conflict\n",
      "share blessing wish pursue choose enter countryman mutual property exercise\n",
      "reason sentiment especially republican abroad exist section ability wise benefit\n",
      "add private mankind\n",
      "\n",
      "topic 14 : pay tax age revenue increase today department race number reduce period debt\n",
      "blessing enterprise prejudice word regard dollar money build election help turn\n",
      "arm domestic poverty promote ago nuclear reason desire deal remember constant\n",
      "respectively safety doubt privilege million expenditure amendment economic local\n",
      "proper afford defense business oppose sentiment protection\n",
      "\n",
      "topic 15 : economic civilization business help democracy federal ideal international ought\n",
      "problem leadership moral mankind trade establish defense desire expression\n",
      "determine promote wish method prove today effective burden tax constitutional\n",
      "expect belief realize increase standard humanity citizenship fail welfare\n",
      "settlement activity deal return sound devotion use independence agency position\n",
      "material benefit cooperation\n",
      "\n",
      "topic 16 : importance help afford exist revenue regard sovereignty today claim defense\n",
      "father desire establish arise position extent mankind rest europe ready term\n",
      "enjoy moment experiment friend understand deal conflict business mark ability\n",
      "perform coast false certain conduct death extend material word employment\n",
      "heretofore pursue example international possible gulf truth protection\n",
      "consequence\n",
      "\n",
      "topic 17 : revenue increase territory proper object protection business ought trade exist\n",
      "extend effect exercise section opinion importance case tariff legislation race\n",
      "department constitutional community promote consideration possible south enter\n",
      "treaty afford term debt pay defense reason domestic happy federal expenditure\n",
      "provision enforce method execute event officer local prevent faithful judgment\n",
      "establish\n",
      "\n",
      "topic 18 : abroad role build today era challenge help structure proud learn promise turn\n",
      "away share resolve greatly retreat mr gladly ashamed bold understand stagnation\n",
      "community recognize merely forward level create democracy expect use fail engage\n",
      "past year confident record indispensable vital boldly enter chance limitation\n",
      "shift initiative test 200th pray conflict remember\n",
      "\n",
      "topic 19 : help extend want revenue recognize constitutional period importance enjoy firm\n",
      "ought territory build domestic wish portion remember example enter beloved\n",
      "attention preparation circumstance improvement equally afford cost dream proper\n",
      "family legislative safe profit value mankind military money debt ability promote\n",
      "effect cheerfully divide predecessor early increase principal pursue endure\n",
      "department\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "print\n",
    "\n",
    "print \n",
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, top_n=50):\n",
    "    print\n",
    "    print 'topic', topic_idx, ':', '\\n'.join(textwrap.wrap(' '.join(top_terms), 80))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
